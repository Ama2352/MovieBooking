# âœ… K6 Load Test Report: Spike Test

## ðŸ“„ Test Scenario Overview

| Attribute | Detail |
| :--- | :--- |
| **Test Script** | `04-spike-test.js` (Stress/Spike Test) |
| **Test Purpose** | To assess the system's **stability and recovery** under a sudden, massive surge in traffic (a spike from 10 VUs to 100 VUs). The goal is to see if the system breaks, hangs, or recovers quickly. |
| **Critical Flow** | Get Available Seats $\rightarrow$ **Attempt to Lock Single Seat** $\rightarrow$ Release Lock |
| **Key Metric** | **Graceful Handling:** Did the system return expected conflicts (409/423) instead of unexpected errors (5xx/timeouts)? |

---

## âš™ï¸ Load Profile (Setup Scenario)

The test implemented a classic **Spike Pattern** using `ramping-vus` to generate a sharp, intense surge in load followed by a quick drop back to baseline for recovery monitoring.

| Phase | Duration | Target Virtual Users (VUs) | Goal |
| :--- | :--- | :--- | :--- |
| **1: Baseline** | 30s | 10 | Normal traffic level. |
| **2: SPIKE!** | **40s** | **Ramp to 100 VUs** | Sudden, 10x load increase in 10s, then sustained. |
| **3: Drop** | 5s | 10 | Quick return to low load. |
| **4: Recovery** | 30s | 10 | Monitor recovery time. |

---

## ðŸš¦ Threshold Assessment Summary

The test **PASSED ALL THRESHOLDS** with excellent results. The system not only handled the 10x spike in traffic gracefully but maintained exceptionally low error rates and fast latency, confirming its resilience against traffic surges.

| Metric | Threshold | Actual Result | Status | Key Insight |
| :--- | :--- | :--- | :--- | :--- |
| **`spike_success_rate`** | Rate $> 50\%$ | **$95.62\%$** | âœ… **PASS** | Vast majority of iterations completed successfully (either locking or handling conflict correctly). |
| **`http_req_failed`** | Rate $< 25\%$ | **$1.47\%$** | âœ… **PASS** | Extremely low rate of unexpected errors (5xx/timeouts), indicating excellent stability. |
| **`spike_latency` p(95)** | $< 5000$ ms | $55$ ms | âœ… **PASS** | Response times remained very fast even during the high-contention spike. |
| **`http_req_duration` p(99)** | $< 8000$ ms | $49.78$ ms | âœ… **PASS** | Nearly all requests were served in under 50ms. |

---

## ðŸ“Š Detailed Metric Analysis

### 1. Stability and Resilience Metrics

These metrics confirm the system successfully transitioned from baseline to peak load and back without breaking.

| Metric | Result | Meaning of Result | Code Line/Logic |
| :--- | :--- | :--- | :--- |
| **`http_req_failed`** | **$1.47\%$** | The rate of unexpected failures (HTTP 5xx, timeouts) is well below the $25\%$ allowance. This means that when the system couldn't grant a seat lock due to the spike, it correctly returned a **409/423 conflict** instead of crashing or timing out. | Tracks all unexpected failures across all HTTP requests. |
| **`spike_success_rate`** | **$95.62\%$** | This rate includes both successful locks and expected conflicts. A high rate here means the test flow completed successfully (either acquiring the lock or gracefully receiving the expected conflict). **Result: PASS.** | Lines 306, 310, 316. |
| **`checks_succeeded`** | **$100.00\%$** | All functional assertions passed, including the checks for successful locks and the checks for valid conflict responses. This proves the **data integrity** of the seat locking mechanism held up under the extreme spike. | Lines 303, 314. |

### 2. Latency and Performance Metrics

The latency figures show impressive performance, demonstrating that the system's architecture (likely Redis for locking) is highly optimized for this high-contention scenario.

| Metric | P95 Result | P99 Result | Insight |
| :--- | :--- | :--- | :--- |
| **`spike_latency` (End-to-End)** | $55$ ms | N/A | $95\%$ of all seat lock attempts (including the time to fetch the seat list) completed in **just 55 milliseconds**. This is extremely fast, especially during a 10x traffic spike. |
| **`http_req_duration` (Overall)** | $25.95$ ms | $49.78$ ms | Even the slowest $1\%$ of all requests still finished in under $50$ ms. The system is highly responsive and showed **no signs of thread exhaustion or slow I/O** during the spike. |
| **`avg=13.18ms`** | N/A | N/A | The average response time across the entire test (baseline, spike, and recovery) remained very low, demonstrating **fast recovery** after the traffic surge. |

---

## ðŸ›‘ Overall Test Conclusion

The **Spike Test PASSED** with outstanding results.

The system demonstrated **exceptional resilience** and **high stability** when subjected to a sudden, 10x increase in load (10 VUs to 100 VUs). The concurrency handling logic performed flawlessly, returning the expected conflict responses instead of unexpected errors.

### Summary of Findings

* **Stability:** Near-zero unexpected error rate ($1.47\%$) proves the system did not crash or suffer resource failures under the spike.
* **Performance:** Latency remained extremely low (P99 $<50$ ms), indicating the system is well-scaled for high-speed transaction processing.
* **Recovery:** The stability and latency results across the entire test duration imply immediate and effective recovery once the spike subsided.

### Recommended Next Steps

1.  **Increase Spike Intensity:** To find the true breaking point, the spike test should be repeated with a higher peak VUs (e.g., $150-200$ VUs) or a sharper ramp-up (e.g., $10 \rightarrow 100$ VUs in $5$ seconds).
2.  **Extended Stress:** Since the system handles brief spikes well, conduct a **Stress Test** at $100-150$ VUs for an extended duration ($5-10$ minutes) to confirm that the stability holds and there are no hidden bottlenecks that emerge over time.