# ğŸ“‰ K6 Load Test Report: Soak Test (Endurance)

## ğŸ“„ Test Scenario Overview

| Attribute | Detail |
| :--- | :--- |
| **Test Script** | `05-soak-test.js` (Endurance Test) |
| **Test Purpose** | To validate the **system's stability and resilience** over an extended period under a **constant, moderate load**, specifically to detect issues like **memory leaks, connection pool exhaustion, and gradual latency degradation.** |
| **Target Endpoint** | Mixed operations (Read-heavy, plus Seat Lock/Release) |
| **Duration** | **20 minutes** |
| **Key Failure Indication** | Gradual increase in error rate or latency over time. |

---

## âš™ï¸ Load Profile (Setup Scenario)

The test used a **Constant VUs** executor to maintain a steady, moderate load throughout the 20-minute duration.

| Attribute | Setting | Description |
| :--- | :--- | :--- |
| **Executor** | `constant-vus` | Maintains stable load for endurance testing. |
| **Virtual Users (VUs)** | **15 VUs** | Constant, moderate load level. |
| **Operation Mix** | 85% Read Operations (Seat Map, Movies, Availability, Showtimes) |
| | 15% Write Operations (Lock & Release Seat) |

---

## ğŸš¦ Threshold Assessment Summary

The test **FAILED** across all three error/success rate thresholds. While response latency remained excellent overall, the **high rate of errors** and the complete failure of the **Seat Availability endpoint** indicate significant stability issues even under moderate, sustained load.

| Metric | Threshold | Actual Result | Status | Key Insight |
| :--- | :--- | :--- | :--- | :--- |
| **`http_req_failed`** | Rate $< 2.0\%$ (0.02) | **$15.70\%$** | âŒ **FAIL** | 7.85x higher than the acceptable error rate. |
| **`soak_errors`** | Count $< 100$ | **$1203$** | âŒ **FAIL** | 12x the maximum tolerable business error count. |
| **`soak_success_rate`** | Rate $> 95\%$ (0.95) | **$79.74\%$** | âŒ **FAIL** | Indicates $20.26\%$ of iterations failed functionally. |
| **`soak_iteration_latency` p(99)** | $< 5000$ ms | $77$ ms | âœ… **PASS** | Latency is excellent and stable; no obvious degradation *in the aggregate latency metric.* |

---

## ğŸ“Š Detailed Metric Analysis

### 1. Stability and Error Metrics (The Failure Point)

The purpose of a soak test is to ensure stability. The error metrics show a clear, definitive failure in stability.

| Metric | Result | Meaning of Result | Code Line/Logic |
| :--- | :--- | :--- | :--- |
| **`soak_errors`** | **1203** | This custom counter tracks any time an operation (Read or Write) fails its k6 `check()`. **Result: FAIL.** This represents a high volume of functional failures. | Line 275: `soakErrors.add(1);` (If `success` is `false`) |
| **`http_req_failed`** | **$15.70\%$** | This k6 core metric tracks unexpected errors (HTTP 5xx, timeouts, connection issues). **Result: FAIL.** The accepted threshold for a soak test is near zero (2%), making 15.70% a severe stability problem. | Tracks all HTTP requests that returned a status outside of 2xx, 3xx, or expected 4xx. |
| **`soak_success_rate`** | **$79.74\%$** | Only about 4 out of 5 iterations were fully successful. **Result: FAIL.** This falls far short of the expected $95\%$ reliability for a moderate load over time. | Line 274: `soakSuccessRate.add(1);` (If `success` is `true`) |

### 2. Check Failure Analysis (The Root Cause)

The check results point directly to the failing component:

* **`soak availability: status 200`** $\rightarrow$ **$0\% \checkmark / 1203 \times$**
    * **Meaning:** This check failed **1203 times** and succeeded **0 times** across all iterations.
    * **Code Context (Lines 216-228):** This check specifically tests the `/seat-locks/availability/{showtimeId}` endpoint (a **Read** operation).
    * **Conclusion:** The **Seat Availability endpoint is fundamentally broken** or failed catastrophically early in the test, causing **all 1203 functional failures**. This is a critical stability issue that must be addressed immediately.

### 3. Performance and Latency Metrics (The Irony)

Despite the functional failure, the overall latency metrics appear excellent:

| Metric | P99 Result | Key Insight | Code Line/Logic |
| :--- | :--- | :--- | :--- |
| **`soak_iteration_latency`** | $77$ ms | The total time for a full iteration (which includes all requests and thinking time) is extremely fast and stable. **NO gradual increase in latency** was detected in this aggregate metric.  | Line 48: `iterationLatency = new Trend('soak_iteration_latency');` |
| **`soak_read_latency`** | $57$ ms | The $99^{th}$ percentile for all read operations is very low. | Line 46: `readLatency = new Trend('soak_read_latency');` |
| **`soak_write_latency`** | $160.15$ ms | Even the Lock & Release operations, which stress Redis and the Database, remain very fast and stable over 20 minutes. | Line 47: `writeLatency = new Trend('soak_write_latency');` |

**Interpretation:** The system is **fast** but **brittle**. It fails *immediately* (as seen by the $0\%$ success on the availability check) rather than gradually slowing down or exhibiting a memory leak characteristic. This points to a **configuration error, a connection failure, or an uncaught exception** within the logic of the `/seat-locks/availability` endpoint itself.

---

## ğŸ›‘ Overall Test Conclusion

The **Soak Test FAILED**. The system is **not stable** and cannot sustain moderate load over a 20-minute period.

### Summary of Findings

1.  **Critical Failure:** The stability thresholds were massively violated (e.g., $15.70\%$ HTTP failure rate vs. $2\%$ goal).
2.  **Root Cause Identified:** All functional failures track back to the **Seat Availability endpoint** (`/seat-locks/availability/{showtimeId}`), which failed **$100\%$** of its attempts.
3.  **No Degradation Detected:** The fact that latency remained excellent and stable (P99 at $77$ ms) suggests there are **NO memory leaks or connection pool exhaustion issues** causing a *gradual slowdown*. The failure is immediate and consistent across the test duration.

### Recommended Next Steps

1.  **Debugging Priority:** Immediately debug the **`/seat-locks/availability/{showtimeId}`** endpoint. Check application logs for error messages (especially 4xx or 5xx responses) corresponding to the requests made to this endpoint during the test run.
2.  **Code Review:** Review the code for the availability endpoint for **unhandled exceptions, database query errors, or improper connection handling** that causes it to fail consistently.
3.  **Re-Test:** After fixing the availability endpoint, re-run the soak test to confirm that all three stability thresholds (`http_req_failed`, `soak_errors`, `soak_success_rate`) are met and that the latency remains flat and low over the full 20-minute duration.